2024-01-24 21:46:02,115 - root - INFO - Flag Values:
{
    "L1_flag": true,
    "batch_size": 512,
    "ckpt_path": "./log/",
    "clipping_max_value": 5.0,
    "data_path": "./datasets/",
    "dataset": "beijing",
    "early_stopping_steps_to_wait": 45750,
    "embedding_size": 128,
    "eval_interval_steps": 9150,
    "eval_only_mode": false,
    "experiment_name": "beijing-transh-1706103962",
    "filter_wrong_corrupted": false,
    "has_visualization": false,
    "is_report": false,
    "joint_ratio": 0.5,
    "kg_lambda": 1.0,
    "kg_test_files": "test.txt",
    "l2_lambda": 0.0,
    "learning_rate": 0.001,
    "learning_rate_decay_when_no_progress": 0.5,
    "load_ckpt_file": null,
    "load_experiment_name": null,
    "log_level": "debug",
    "log_path": "./log/",
    "margin": 1.0,
    "max_queue": 10,
    "model_type": "transh",
    "momentum": 0.9,
    "negtive_samples": 1,
    "norm_lambda": 1.0,
    "num_preferences": 4,
    "num_processes": 1,
    "optimizer_type": "Adam",
    "rec_test_files": null,
    "seed": 3,
    "share_embeddings": false,
    "topn": 10,
    "training_steps": 915000,
    "use_st_gumbel": false,
    "version": "",
    "visualization_port": 8097
}
2024-01-24 21:46:06,618 - root - INFO - Totally 1366016 train triples, 0 eval triples in files: ./datasets/beijing\test.txt!
2024-01-24 21:46:06,650 - root - INFO - successfully load 28342 entities and 3 relations!
2024-01-24 21:46:07,238 - root - INFO - Building model.
2024-01-24 21:46:10,701 - root - INFO - Architecture: TransHModel(
  (ent_embeddings): Embedding(28342, 128)
  (rel_embeddings): Embedding(3, 128)
  (norm_embeddings): Embedding(3, 128)
)
2024-01-24 21:46:10,704 - root - INFO - Total params: 3628544.0
2024-01-24 21:46:10,704 - root - INFO - One epoch is 2668 steps.
2024-01-24 21:46:10,704 - root - INFO - Training.
2024-01-24 21:57:14,307 - root - INFO - train loss:39.4272!
2024-01-24 21:57:14,316 - root - INFO - Checkpointing ...
2024-01-24 21:57:14,346 - root - INFO - Lowering learning rate every 20 epochs.
2024-01-24 22:06:56,897 - root - INFO - train loss:14.7494!
2024-01-24 22:06:56,897 - root - INFO - Checkpointing ...
2024-01-24 22:06:56,930 - root - INFO - Lowering learning rate every 20 epochs.
2024-01-24 22:16:16,828 - root - INFO - train loss:11.0215!
2024-01-24 22:16:16,828 - root - INFO - Checkpointing ...
2024-01-24 22:16:16,848 - root - INFO - Lowering learning rate every 20 epochs.
2024-01-24 22:25:31,650 - root - INFO - train loss:9.2612!
2024-01-24 22:25:31,650 - root - INFO - Checkpointing ...
2024-01-24 22:25:31,682 - root - INFO - Lowering learning rate every 20 epochs.
2024-01-24 22:34:48,389 - root - INFO - train loss:8.3842!
2024-01-24 22:34:48,389 - root - INFO - Checkpointing ...
2024-01-24 22:34:48,419 - root - INFO - Lowering learning rate every 20 epochs.
